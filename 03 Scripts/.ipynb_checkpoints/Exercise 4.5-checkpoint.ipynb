{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a801de-0715-4a48-9f76-44cff908166d",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f1bb88-fcca-4c82-88fa-7c2a8f59076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0309daa3-dcd2-48e6-9351-726990f664da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing “products.csv” data set from the “Original Data” folder as df_prods by creating a string of the path\n",
    "path = r'C:\\Users\\rbhte\\Documents\\Achievement_4_Monami\\Instacart Basket Analysis'\n",
    "df_prods = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', '4.3_orders_products', 'products.csv'), index_col = 0)\n",
    "# Importing “orders_wrangled.csv” data set from the “Prepared Data” folder as df_ords by creating a string of the path\n",
    "df_ords = pd.read_csv(os.path.join(path, '02 Data', 'Prepared Data', 'orders_wrangled.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3ccf6-7e98-4b0e-b9d8-80d67c45400f",
   "metadata": {},
   "source": [
    "# To perform consistency checks on the orders dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77a9da4-7063-4d37-ad78-19a89ba2a97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.214874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.029782e+05</td>\n",
       "      <td>1.715486e+01</td>\n",
       "      <td>2.776219e+00</td>\n",
       "      <td>1.345202e+01</td>\n",
       "      <td>1.111484e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.875817e+05</td>\n",
       "      <td>5.953372e+04</td>\n",
       "      <td>1.773316e+01</td>\n",
       "      <td>2.046829e+00</td>\n",
       "      <td>4.226088e+00</td>\n",
       "      <td>9.206737e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.552715e+05</td>\n",
       "      <td>5.139400e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.026890e+05</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.565812e+06</td>\n",
       "      <td>1.543850e+05</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>2.062090e+05</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id       user_id  order_number  order_day_of_week  \\\n",
       "count  3.421083e+06  3.421083e+06  3.421083e+06       3.421083e+06   \n",
       "mean   1.710542e+06  1.029782e+05  1.715486e+01       2.776219e+00   \n",
       "std    9.875817e+05  5.953372e+04  1.773316e+01       2.046829e+00   \n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00       0.000000e+00   \n",
       "25%    8.552715e+05  5.139400e+04  5.000000e+00       1.000000e+00   \n",
       "50%    1.710542e+06  1.026890e+05  1.100000e+01       3.000000e+00   \n",
       "75%    2.565812e+06  1.543850e+05  2.300000e+01       5.000000e+00   \n",
       "max    3.421083e+06  2.062090e+05  1.000000e+02       6.000000e+00   \n",
       "\n",
       "       order_hour_of_day  days_since_prior_order  \n",
       "count       3.421083e+06            3.214874e+06  \n",
       "mean        1.345202e+01            1.111484e+01  \n",
       "std         4.226088e+00            9.206737e+00  \n",
       "min         0.000000e+00            0.000000e+00  \n",
       "25%         1.000000e+01            4.000000e+00  \n",
       "50%         1.300000e+01            7.000000e+00  \n",
       "75%         1.600000e+01            1.500000e+01  \n",
       "max         2.300000e+01            3.000000e+01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating the accuracy of the columns in the dataframe\n",
    "df_ords.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81eae69a-b7e5-4a2d-8014-1735db63f4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_day_of_week stats:\n",
      "Min: 0\n",
      "Max: 6\n",
      "Unique values: [2 3 4 1 5 0 6]\n"
     ]
    }
   ],
   "source": [
    "# Check min, max and unique values\n",
    "print(\"order_day_of_week stats:\")\n",
    "print(f\"Min: {df_ords['order_day_of_week'].min()}\")\n",
    "print(f\"Max: {df_ords['order_day_of_week'].max()}\")\n",
    "print(f\"Unique values: {df_ords['order_day_of_week'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee3563-c3db-47d3-85ca-fa8d55b55fb9",
   "metadata": {},
   "source": [
    "Expected : Min: 0 (Sunday), Max: 6 (Saturday), Total unique values: 7, Median (50th percentile): 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b587f49-369d-4f39-a7e2-4b05de582bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_since_prior_order stats:\n",
      "Min: 0.0\n",
      "Max: 30.0\n",
      "Number of NaN values: 206209\n"
     ]
    }
   ],
   "source": [
    "# Check min, max and unique values\n",
    "print(\"days_since_prior_order stats:\")\n",
    "print(f\"Min: {df_ords['days_since_prior_order'].min()}\")\n",
    "print(f\"Max: {df_ords['days_since_prior_order'].max()}\")\n",
    "print(f\"Number of NaN values: {df_ords['days_since_prior_order'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c3c00-76ca-44cc-9ca1-5ada331b72bb",
   "metadata": {},
   "source": [
    "Expected : No negative values, Max should be reasonable based on the dataset's time range, NaN values are okay since it represents first-time orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4791c2ce-d62b-4721-9f77-9e098f44a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_hour_of_day stats:\n",
      "Min: 0\n",
      "Max: 23\n",
      "Unique values: [ 8  7 12 15  9 14 16 11 10 19 18 17 13 20  0 21 22  5 23  4  6  1  2  3]\n"
     ]
    }
   ],
   "source": [
    "# Check min, max and unique values\n",
    "print(\"order_hour_of_day stats:\")\n",
    "print(f\"Min: {df_ords['order_hour_of_day'].min()}\")\n",
    "print(f\"Max: {df_ords['order_hour_of_day'].max()}\")\n",
    "print(f\"Unique values: {df_ords['order_hour_of_day'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e17403-00fc-4a7c-9982-913241d56e6d",
   "metadata": {},
   "source": [
    "Expected : Min: 0 (earliest time of day), Max: 23 (latest time of day), No values outside this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d364ae-feab-4cd9-8f2e-f97bb8fe3ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id: [<class 'int'>]\n",
      "user_id: [<class 'int'>]\n",
      "order_number: [<class 'int'>]\n",
      "order_day_of_week: [<class 'int'>]\n",
      "order_hour_of_day: [<class 'int'>]\n",
      "days_since_prior_order: [<class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "# Checking whether the df_ords dataframe contains any mixed-type columns\n",
    "for col in df_ords.columns:\n",
    "    mixed_types = df_ords[col].apply(lambda x: type(x)).unique()\n",
    "    print(f\"{col}: {mixed_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1af1a-a753-435b-80e3-f1498c966c7f",
   "metadata": {},
   "source": [
    "There are no mixed-type columns in this DataFrame (df_ords). Each column contains consistent data types across all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7108c2-74be-4262-a370-173335e1ca9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                       0\n",
      "user_id                        0\n",
      "order_number                   0\n",
      "order_day_of_week              0\n",
      "order_hour_of_day              0\n",
      "days_since_prior_order    206209\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# To find the missing values if any\n",
    "missing_values = df_ords.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d7ca9-f9e8-4a02-83cf-adad52ccab07",
   "metadata": {},
   "source": [
    "This is a good method of choice because :\n",
    "\n",
    "isnull(): This function returns a DataFrame of the same shape, where each element is a boolean (True if the value is missing, False otherwise).\n",
    "\n",
    "sum(): When applied to the result of isnull(), it counts the number of True values (i.e., missing values) for each column. This gives us a concise summary of how many missing values exist in each column of the dataframe.\n",
    "\n",
    "Using this method we can quickly assess the presence of any missing data in the modified dataframe without affecting the original dataframe. It's efficient for large datasets because it directly gives us the count of missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28d4232-8438-4b32-b894-97727b49750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         order_id  user_id  order_number  order_day_of_week  \\\n",
      "0         2539329        1             1                  2   \n",
      "11        2168274        2             1                  2   \n",
      "26        1374495        3             1                  1   \n",
      "39        3343014        4             1                  6   \n",
      "45        2717275        5             1                  3   \n",
      "...           ...      ...           ...                ...   \n",
      "3420930    969311   206205             1                  4   \n",
      "3420934   3189322   206206             1                  3   \n",
      "3421002   2166133   206207             1                  6   \n",
      "3421019   2227043   206208             1                  1   \n",
      "3421069   3154581   206209             1                  3   \n",
      "\n",
      "         order_hour_of_day  days_since_prior_order  \n",
      "0                        8                     NaN  \n",
      "11                      11                     NaN  \n",
      "26                      14                     NaN  \n",
      "39                      11                     NaN  \n",
      "45                      12                     NaN  \n",
      "...                    ...                     ...  \n",
      "3420930                 12                     NaN  \n",
      "3420934                 18                     NaN  \n",
      "3421002                 19                     NaN  \n",
      "3421019                 15                     NaN  \n",
      "3421069                 11                     NaN  \n",
      "\n",
      "[206209 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Now we need to see the missing values in days_since_prior_order\n",
    "df_dspo = df_ords[df_ords['days_since_prior_order'].isnull() == True]\n",
    "print (df_dspo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28b81e-3f38-43b9-8e11-7d858c71c715",
   "metadata": {},
   "source": [
    "The `NaN` values in the `days_since_prior_order` column represent customers' first orders, as no prior order exists. These are not errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d359c16-6a69-4334-8f0e-7bc40988ffaa",
   "metadata": {},
   "source": [
    "Addressing Missing Values in days_since_prior_order\n",
    "\n",
    "1. Remove or Filter Out Missing Data:\n",
    "Removing missing values isn’t suitable here because NaN represents \"new customers\" with no prior orders. This missing information is meaningful and shouldn't be discarded.\n",
    "\n",
    "2. Impute Values with Mean or Median:\n",
    "Imputing values isn’t feasible as NaN indicates no prior orders, not a typical numerical value. Using the mean (e.g., 11.11) or zero would misrepresent this scenario, as it doesn't capture the concept of a new customer.\n",
    "\n",
    "3. Create a New Flag Variable:\n",
    "The best approach is to preserve the NaN values and create a new column, such as \"new_customer\", where True indicates a new customer (NaN in days_since_prior_order) and False otherwise. This way, the missing values are flagged and retain their importance without altering the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727227cb-55f3-409c-9e47-cfcad4389ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_ords.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "439fbe57-1688-4893-84fb-a4283ab8252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    days_since_prior_order  new_customer\n",
      "0                      NaN          True\n",
      "1                     15.0         False\n",
      "2                     21.0         False\n",
      "3                     29.0         False\n",
      "4                     28.0         False\n",
      "5                     19.0         False\n",
      "6                     20.0         False\n",
      "7                     14.0         False\n",
      "8                      0.0         False\n",
      "9                     30.0         False\n",
      "10                    14.0         False\n",
      "11                     NaN          True\n",
      "12                    10.0         False\n",
      "13                     3.0         False\n",
      "14                     8.0         False\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataframe\n",
    "df_ords_modified = df_ords.copy()\n",
    "\n",
    "# Create the 'new_customer' column\n",
    "df_ords_modified['new_customer'] = df_ords_modified['days_since_prior_order'].isnull()\n",
    "\n",
    "# Verify the result\n",
    "print(df_ords_modified[['days_since_prior_order', 'new_customer']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "270b9f71-ff39-44bf-b658-326409aaebfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                       0\n",
       "user_id                        0\n",
       "order_number                   0\n",
       "order_day_of_week              0\n",
       "order_hour_of_day              0\n",
       "days_since_prior_order    206209\n",
       "new_customer                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To recheck and see if there are any missing values \n",
    "df_ords_modified.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcd43ff2-fe5d-40fa-a5a7-65268dfaeefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [order_id, user_id, order_number, order_day_of_week, order_hour_of_day, days_since_prior_order, new_customer]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# To look for duplicates in df_ords_modified\n",
    "df_ords_cleaned = df_ords_modified[df_ords_modified.duplicated()]\n",
    "print (df_ords_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c07faf-5ad1-4521-845e-07cdb9ff0f34",
   "metadata": {},
   "source": [
    "The duplicated() function checks for rows that are exact copies of other rows in the DataFrame. Since the resulting DataFrame df_ords_cleaned is empty, it means that all rows in df_ords_modified are unique. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4505a-ce4f-4b51-8cf8-c1a68d7f885f",
   "metadata": {},
   "source": [
    "# To perform consistency checks on the products dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e1445ce-7724-4c95-a9ce-adc8a3024588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49693.000000</td>\n",
       "      <td>49693.000000</td>\n",
       "      <td>49693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.770249</td>\n",
       "      <td>11.728433</td>\n",
       "      <td>9.994136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.316774</td>\n",
       "      <td>5.850282</td>\n",
       "      <td>453.519686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           aisle_id  department_id        prices\n",
       "count  49693.000000   49693.000000  49693.000000\n",
       "mean      67.770249      11.728433      9.994136\n",
       "std       38.316774       5.850282    453.519686\n",
       "min        1.000000       1.000000      1.000000\n",
       "25%       35.000000       7.000000      4.100000\n",
       "50%       69.000000      13.000000      7.100000\n",
       "75%      100.000000      17.000000     11.200000\n",
       "max      134.000000      21.000000  99999.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating the accuracy of the columns in the dataframe\n",
    "df_prods.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3006e816-d015-4134-9824-43310feea5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values for each column:\n",
      "aisle_id unique values: 134\n",
      "department_id unique values: 21\n",
      "prices unique values: 242\n",
      "\n",
      "Min and Max values:\n",
      "aisle_id: min=1, max=134\n",
      "department_id: min=1, max=21\n",
      "prices: min=1.0, max=99999.0\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values for each column\n",
    "print(\"\\nUnique values for each column:\")\n",
    "print(f\"aisle_id unique values: {df_prods['aisle_id'].nunique()}\")\n",
    "print(f\"department_id unique values: {df_prods['department_id'].nunique()}\")\n",
    "print(f\"prices unique values: {df_prods['prices'].nunique()}\")\n",
    "\n",
    "# Check the min and max values for specific columns\n",
    "print(\"\\nMin and Max values:\")\n",
    "print(f\"aisle_id: min={df_prods['aisle_id'].min()}, max={df_prods['aisle_id'].max()}\")\n",
    "print(f\"department_id: min={df_prods['department_id'].min()}, max={df_prods['department_id'].max()}\")\n",
    "print(f\"prices: min={df_prods['prices'].min()}, max={df_prods['prices'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab923060-f31e-4874-b848-11da29055de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id: [<class 'int'>]\n",
      "product_name: [<class 'str'> <class 'float'>]\n",
      "aisle_id: [<class 'int'>]\n",
      "department_id: [<class 'int'>]\n",
      "prices: [<class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "# Temporarily reset the index to include product_id as a column\n",
    "df_prods_reset = df_prods.reset_index()\n",
    "\n",
    "# Check for mixed-type data\n",
    "for col in df_prods_reset.columns:\n",
    "    mixed_types = df_prods_reset[col].apply(lambda x: type(x)).unique()\n",
    "    print(f\"{col}: {mixed_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "843810e4-f961-4765-a052-50d34cc4fbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id product_name  aisle_id  department_id  prices\n",
      "33             34          NaN       121             14    12.2\n",
      "68             69          NaN        26              7    11.8\n",
      "115           116          NaN        93              3    10.8\n",
      "261           262          NaN       110             13    12.1\n",
      "525           525          NaN       109             11     1.2\n",
      "1511         1511          NaN        84             16    14.3\n",
      "1780         1780          NaN       126             11    12.3\n",
      "2240         2240          NaN        52              1    14.2\n",
      "2586         2586          NaN       104             13    12.4\n",
      "3159         3159          NaN       126             11    13.1\n",
      "3230         3230          NaN       120             16    14.4\n",
      "3736         3736          NaN        41              8    14.8\n",
      "4283         4283          NaN        77              7    14.4\n",
      "4790         4790          NaN        91             16    14.5\n",
      "38187       38183          NaN        39             12    20.9\n",
      "40444       40440          NaN       120             16    14.8\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with mixed types in product_name\n",
    "problematic_rows = df_prods_reset[df_prods_reset['product_name'].apply(lambda x: not isinstance(x, str))]\n",
    "print(problematic_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e432ca3f-2933-46ee-a522-19b9c74726ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49693, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prods_reset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11426fdc-329d-457e-ac6d-1218b8649ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to fix the issue\n",
    "df_prods_modified = df_prods_reset[df_prods_reset['product_name'].isnull() == False ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "613d0646-647f-4733-a9be-a34da874a024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49677, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prods_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fb94292-b7cf-44b3-9ea2-b8b8f601d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id: [<class 'int'>]\n",
      "product_name: [<class 'str'>]\n",
      "aisle_id: [<class 'int'>]\n",
      "department_id: [<class 'int'>]\n",
      "prices: [<class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "# Check for mixed types again in the modified dataframe\n",
    "for col in df_prods_modified.columns:\n",
    "    mixed_types = df_prods_modified[col].apply(lambda x: type(x)).unique()\n",
    "    print(f\"{col}: {mixed_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "627c6bc1-0af3-40ae-9e6f-e1a95111a534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id       0\n",
      "product_name     0\n",
      "aisle_id         0\n",
      "department_id    0\n",
      "prices           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in df_prods_modified\n",
    "missing_values = df_prods_modified.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3da4b98-f722-4818-8113-55ba2c32c658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id                                       product_name  \\\n",
      "462           462                  Fiber 4g Gummy Dietary Supplement   \n",
      "18459       18458                                         Ranger IPA   \n",
      "26810       26808               Black House Coffee Roasty Stout Beer   \n",
      "35309       35306  Gluten Free Organic Peanut Butter & Chocolate ...   \n",
      "35495       35491                            Adore Forever Body Wash   \n",
      "\n",
      "       aisle_id  department_id  prices  \n",
      "462          70             11     4.8  \n",
      "18459        27              5     9.2  \n",
      "26810        27              5    13.4  \n",
      "35309       121             14     6.8  \n",
      "35495       127             11     9.9  \n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in df_prods_modified\n",
    "duplicates = df_prods_modified[df_prods_modified.duplicated()]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79b2c9d4-bbe6-400a-82ec-589dbbc4d1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 5\n"
     ]
    }
   ],
   "source": [
    "# Count the number of duplicate rows\n",
    "num_duplicates = df_prods_modified.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30343f6b-7611-47bc-a1ad-e503dfa2e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The modified dataframe without duplicates : \n",
      "       product_id                                       product_name  \\\n",
      "0               1                         Chocolate Sandwich Cookies   \n",
      "1               2                                   All-Seasons Salt   \n",
      "2               3               Robust Golden Unsweetened Oolong Tea   \n",
      "3               4  Smart Ones Classic Favorites Mini Rigatoni Wit...   \n",
      "4               5                          Green Chile Anytime Sauce   \n",
      "...           ...                                                ...   \n",
      "49688       49684          Vodka, Triple Distilled, Twist of Vanilla   \n",
      "49689       49685                 En Croute Roast Hazelnut Cranberry   \n",
      "49690       49686                                   Artisan Baguette   \n",
      "49691       49687         Smartblend Healthy Metabolism Dry Cat Food   \n",
      "49692       49688                             Fresh Foaming Cleanser   \n",
      "\n",
      "       aisle_id  department_id  prices  \n",
      "0            61             19     5.8  \n",
      "1           104             13     9.3  \n",
      "2            94              7     4.5  \n",
      "3            38              1    10.5  \n",
      "4             5             13     4.3  \n",
      "...         ...            ...     ...  \n",
      "49688       124              5     5.3  \n",
      "49689        42              1     3.1  \n",
      "49690       112              3     7.8  \n",
      "49691        41              8     4.7  \n",
      "49692        73             11    13.5  \n",
      "\n",
      "[49672 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates by keeping the first occurrence\n",
    "df_prods_modified_no_duplicates = df_prods_modified.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Alternatively, we can keep the last occurrence instead of the first by changing 'first' to 'last'\n",
    "# df_prods_modified_no_duplicates = df_prods_modified.drop_duplicates(keep = 'last')\n",
    "\n",
    "print ('\\n The modified dataframe without duplicates : ')\n",
    "print (df_prods_modified_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02c6b27b-2c5c-4d48-aa55-52c861d6b01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49672, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prods_modified_no_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca7e1824-3445-45bd-b0b9-9f6789fc277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the df_ords_modified dataframe as “orders_cleaned.csv” into the “Prepared Data” folder\n",
    "df_ords_modified.to_csv(os.path.join(path, '02 Data','Prepared Data', 'orders_cleaned.csv'))\n",
    "# Exporting the df_prods_modified_no_duplicates dataframe as “products_cleaned.csv” into the “Prepared Data” folder\n",
    "df_prods_modified_no_duplicates.to_csv(os.path.join(path, '02 Data','Prepared Data', 'products_cleaned.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08909f23-2468-4579-ab69-713ed2851919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
