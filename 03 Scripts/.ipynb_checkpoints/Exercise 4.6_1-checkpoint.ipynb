{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5060cef-dba0-46ce-b49d-3c5bc20a9dba",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "456cb020-eefb-4675-9b94-c7ab1982eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e96aedb8-80d0-4848-aed0-24fb6e029fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbhte\\Documents\\Achievement_4_Monami\\Instacart Basket Analysis\n",
      "   product_id                                       product_name  aisle_id  \\\n",
      "0           1                         Chocolate Sandwich Cookies        61   \n",
      "1           2                                   All-Seasons Salt       104   \n",
      "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
      "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
      "4           5                          Green Chile Anytime Sauce         5   \n",
      "\n",
      "   department_id  prices  \n",
      "0             19     5.8  \n",
      "1             13     9.3  \n",
      "2              7     4.5  \n",
      "3              1    10.5  \n",
      "4             13     4.3  \n"
     ]
    }
   ],
   "source": [
    "# Importing “products_cleaned.csv” data set from the “Prepared Data” folder as df_prods by creating a string of the path\n",
    "\n",
    "path = r'C:\\Users\\rbhte\\Documents\\Achievement_4_Monami\\Instacart Basket Analysis'\n",
    "print (path)\n",
    "\n",
    "df_prods_c = pd.read_csv(os.path.join(path, '02 Data', 'Prepared Data', 'products_cleaned.csv'), index_col = 0)\n",
    "print (df_prods_c.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbb7fcbb-63e3-4f50-9cf0-b13d1e962e56",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "deallocated bytearray object has exported buffers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mSystemError\u001b[0m: deallocated bytearray object has exported buffers"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing “orders_products_combined.pkl” data set from the “Prepared Data” folder as df_opc\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Correctly reading the pickle file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_opc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02 Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrepared Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morders_products_combined.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Displaying the first few rows of the DataFrame\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_opc\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;66;03m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[1;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing “orders_products_combined.pkl” data set from the “Prepared Data” folder as df_opc\n",
    "\n",
    "# Correctly reading the pickle file\n",
    "df_opc = pd.read_pickle(os.path.join(path, '02 Data', 'Prepared Data', 'orders_products_combined.pkl'))\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "print(df_opc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3b0c121-c58e-4dcf-ac3d-b30190898402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32640698, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the imported dataframe \n",
    "df_opc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcf54bbf-2703-4bec-81b3-78a36f76669e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49672, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the products dataframe\n",
    "df_prods_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca711094-1893-4f68-b909-b0365417f1d3",
   "metadata": {},
   "source": [
    "# A suitable way to combine the orders_products_combined dataframe (df_opc) with the products data set (df_prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1ab97d-d2c4-4857-9840-d15ae65593f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_opc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_opc\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_opc' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_opc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64f82011-1892-4eaf-90f9-6dda72fbf459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id  order_number  order_day_of_week  order_hour_of_day  \\\n",
      "0         1   112108             4                  4                 10   \n",
      "1         2   202279             3                  5                  9   \n",
      "2         2   202279             3                  5                  9   \n",
      "3         2   202279             3                  5                  9   \n",
      "4         2   202279             3                  5                  9   \n",
      "\n",
      "   days_since_prior_order  new_customer  product_id  add_to_cart_order  \\\n",
      "0                     9.0         False         NaN                NaN   \n",
      "1                     8.0         False     33120.0                1.0   \n",
      "2                     8.0         False     28985.0                2.0   \n",
      "3                     8.0         False      9327.0                3.0   \n",
      "4                     8.0         False     45918.0                4.0   \n",
      "\n",
      "   reordered  \n",
      "0        NaN  \n",
      "1        1.0  \n",
      "2        1.0  \n",
      "3        0.0  \n",
      "4        1.0  \n"
     ]
    }
   ],
   "source": [
    "print(df_opc.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f3112-791b-4e88-9b73-abf8a38b4f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
